```{python imports, echo=False, results=False}
import sys
# BIDev\'s Path
# sys.path.insert(0, 'C:\\Users\\mad221\\PycharmProjects\\Hourly_Predictions')
# Tom's path
sys.path.insert(0, 'C:/Users/tfn/PycharmProjects/Hourly_Predictions')
# Austin's path
#sys.path.insert(0, 'C:/Python/PyProjects/Hourly_Predictions')
import pickle
import xgboost as xgb
import pandas as pd
import numpy as np
from TextMiningMachine.splitting import TrainTestDateSplitter
import math
import datetime
from TextMiningMachine.utils import generate_column_from_search
from TextMiningMachine.plot_methods import plot_regress_corr, plot_shap,plot_shap_univar,plot_cutoff_accuracy,plot_shap_multivar,plot_classification_metrics
import matplotlib.pyplot as plt
import datetime

target_col = 'MetSIRS4_24'
date_col = 'CENSUS_DATE'
# load raw data
data = pd.read_pickle('data/raw_data.p')
data = data.loc[data['NoSIRS4_12']==1,:]
data[date_col] = data['AVAILABLE_TIME'].dt.date
data = data.reset_index()
# load transform
with open( 'models/text_cat_transformer.p', 'rb') as f:
    trans = pickle.load(f)


features = xgb.DMatrix(trans.transform(data), feature_names=trans.feature_names)
# load preproccessed features
#features = xgb.DMatrix( 'data/xgb.features.data')
features.feature_names = trans.feature_names

cut_date = datetime.date(2018, 6, 15)

# cut by date
s = TrainTestDateSplitter()
test, train, y_test, y_train = s.split(data, target_col, date_col, cut_date, features=features)
#load model
model = pd.read_pickle('models/sirs4_24hrs.p')

test_index = s.test_index
train_index = s.train_index
test_raw = data.iloc[test_index]
train_raw = data.iloc[train_index]
```

```{python, predictions, echo=False,  results=False}
from sklearn.metrics import roc_curve, auc
preds_test = model.predict(test)
fpr, tpr, _ = roc_curve(y_test, preds_test)
preds_train = model.predict(train)
fpr_t, tpr_t, _ = roc_curve(y_train, preds_train)
y_train=train.get_label()
y_test = test.get_label()
```

####Objective to Predict Probability of A Patient Meeting SIRS-4 Criteria within 24 hours

The objective of this model is to flag patients who will develop sepsis within 24 hours.
The training data for the model was developed from the MUSC 'Hourly Labs and Vitals' pipeline.
Details are in the repository readme.  A combination of categorical,semi-structured, and numeric data were used to build
the model. All labs, vitals, and other features used in the generation of the model are mentioned below in the 'Variables Considered'
section.

SIRS-4 Criteria is the clinical way that nurses and physicians classify adult inpatients as having sepsis.
Using SIRS-4 criteria, a person is considered to have sepsis when they have all of the following:

(1) Temperature > 100.9 or < 96.8 (and)

(2) HR > 90 (and)

(3) Respiration rate > 20 (and)

(4) White Blood Cell Count > 12 or < 4

The flag for the logistic regression performed was generated by first identifying which patients satisfied SIRS-4 criteria,
when the SIRS-4 criteria was met, and flagging the 24 hours of data prior to the reading.

#### Modeling Approach

The text data was run through a tokenizer to build a bag of words representation, with stop words removed. 
 The modeling technique used was gradient boosted tree via the xgboost package.  The data by using a cut off date, 
 all observations after  cut off date were in the test set. 
 The models were build using two optimizers, to maximize AUC and minimize miss classification log loss. 
  L1 and L2 regularization grid search was used to optimize the model

#### Variables Considered

The following variables were used to build the model.  The text columns are semi-structured and put into a bag of words model.  Catagorical columns were one hot encoded.  All numeric variables were zero imputed when missing.

```{python, variables, echo=False, results = 'tex'}
# training variables
print(trans.col_dict)
# final number of features
print('number of features : ', train.num_col() )
```

#### Holdout Set

```{python, echo=False, results = 'tex'}
print('testing rows : ', test.num_row())
print('training rows : ', train.num_row())
```

#### AUC of the ROC Curve
In a ROC curve, the true positive rate (Sensitivity) is plotted in function of the false positive rate (Specificity) for different cut-off values. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold.

```{python, AUC_Plot, echo=False}
# Calculate the AUC
roc_auc = auc(fpr, tpr)
roc_auc_t = auc(fpr_t, tpr_t)
#print('ROC AUC: %0.2f' % roc_auc)
plt.figure()
plt.plot(fpr, tpr, label='Test AUC  %0.2f' % roc_auc)
plt.plot(fpr_t, tpr_t, label='Train AUC %0.2f' % roc_auc_t)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()
```

#### Sensitvity and Specificity Curves
Sensitivity (true positive rate) is the proportion of cases where the model predicts positive given that the target variable is present. Specificity (true negative rate) is the proportion of cases where the model predicts negative given that the target variable is absent.

```{python,Sen_Spec_Curve,echo=False, evaluate=True,results = 'hidden'}
import pylab as pl
fpr, tpr, thresholds = roc_curve(y_test, preds_test)
roc_auc = auc(fpr, tpr)
#print("Area under the ROC curve : %f" % roc_auc)
i = np.arange(len(tpr)) # index for df
roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})

roc.iloc[(roc.tf-0).abs().argsort()[:1]]

# Plot tpr vs 1-fpr
fig, ax = pl.subplots()
pl.plot(roc['tpr'], color='orange', label='sensitivity')
pl.plot(roc['1-fpr'], color = 'blue', label='specifity')
pl.xlabel('Cut Off')
pl.ylabel('Sensitiviy | Specificity')
pl.title('Sensitivity, Specificity vs Cut Off')
ax.set_xticklabels([])
plt.legend()
```
##### Predicted Probability Distribution
The distribution of model prediction is shown below. The red line represents the proportion of cases where the target variable is present.

```python Density Plots, echo = False
import seaborn as sns
import matplotlib.pyplot as plt
fig, ax = plt.subplots(figsize=(4,4))
sns.distplot( preds_test, hist=False)
plt.axvline(sum(y_test)/len(y_test), color='r')
plt.title("Distribution of Predicted Probablities", loc='right')
plt.xlabel('Probablity')
plt.ylabel('Density')
plt.show()


```

#### Accuracy vs. Cutoff Plot
This plot displays the trade-off between cutoff value and accuracy. Optimal cutoff here is found by maximizing accuracy of model. This is not ideal with problems that have class imbalance; however, optimal cutoffs can be chosen when intervention costs are known.

```{python, accuracy_vs_cutoff, echo = False}
cut = plot_cutoff_accuracy(y_train, y_test, preds_train, preds_test)
```


#### Model Metrics using Using Specified Cutoff
Sensitivity (true positive rate) is the proportion of cases where the model predicts positive when the target variable is present. Specificity (true negative rate) is the proportion of cases where the model predicts negative when the target variable is absent. Positive predictive value is the proportion of cases where the target variable is present when the model predicts positive. Negative predictive value is the proportion of cases where the target variable is absent when the model predicts negative.

#### Classification Plot using Optimal Cutoff Above
```{python, fig = True, width=850, name='model_metrics', echo = False,evaluate=True}
plot_classification_metrics(y_train, y_test, preds_train, preds_test, cut)
```


#### Variable Importance
The variable importance plots display the most important features by their information gain, which is a measurement that sums up how much 'information' a feature gives about the target variable. Information gain measures the reduction in entropy, or uncertainty, over each of the times that the given feature is split on.

```{python, variable_importance, width=850, echo=False,results = 'hidden'}
importances = model.get_score(importance_type='gain')
importance_frame = pd.DataFrame({'Importance': list(importances.values()), 'Feature': list(importances.keys())})
importance_frame.sort_values(by = 'Importance', inplace=True)
importance_frame = importance_frame.tail(25)
importance_frame.plot(x ='Feature', y='Importance' ,kind='barh',legend=False )
```



##### SHAP Univariate Plots
SHapley Additive exPlanations(SHAP) is an approach to explain the output of machine learning models. SHAP assigns a value to each feature for each prediction (i.e. feature attribution); the higher the value, the larger the featureâ€™s attribution to the specific prediction. In cases of classification, a positive SHAP value indicates that a factor increases the value of the model's prediction(risk), whereas a negative SHAP value indicates that a factor decreases the value of the model's prediction. The sum of SHAP values over all features will approximately equal the model prediction for each observation. In the following plots blue points signify negative SHAP values, red points have positive SHAP values, and yellow points are values for which the feature attributes little to predicted value.

```{python, fig = True, width=400, name = 'SHAP 1',echo=False, evaluate=True,results = 'hidden'}

np.random.seed(2012)
import shap
import gc
gc.enable()
import random
from scipy import sparse

## generate samples for sensitivity plots( this needs to go before the importance_frame code )
samp_size=10000
rand_inds = np.sort(random.sample(range(data.shape[0]),samp_size))
samp_data=trans.transform(data.iloc[rand_inds,:])
samp_data = sparse.csc_matrix(samp_data)
shap_vals = model.predict(xgb.DMatrix(samp_data,feature_names=model.feature_names),pred_contribs=True)
samp_df = pd.DataFrame(samp_data.todense())
samp_df.columns=model.feature_names

plt.figure()
plot_shap_univar('MetWBC', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False)
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxRR8', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-2,50))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxRR24', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-2,60))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxTemp24', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('CPM S16 R AS SC BRADEN SCORE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(5,24))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxTemp48', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxTemp8', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('UREA NITROGEN  BLOOD (BUN)', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False, xlim=(0,100))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxHR8', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(30,180))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MinTemp24', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('FIO2  ARTERIAL', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-10,110))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('WEIGHT and SCALE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(400,2000))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxHR24', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(30,180))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('PULSE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(30,200))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxHR48', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(30,180))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MaxWBC48', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-3,75))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MinTemp48', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('LYMPHOCYTES ABSOLUTE COUNT', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(0,1))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('R IP FN WEIGHT CHANGE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-50,50))
```
```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('ORAL INTAKE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(-50,2000))
```

```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('TEMPERATURE', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(88,106))
```

```{python, fig = True, width=400, name = 'SHAP',echo=False, evaluate=True, results = 'hidden'}
plt.figure()
plot_shap_univar('MUSC IP R AVPU (TRANSFORMED)', shap_vals, samp_df,feature_names = samp_df.columns,logged_col=False,xlim=(0,5))
```

##### SHAP Summary Plot Over Categorical/Text Columns
The following plot display the effect of the top text/category values on the Model's predictions. Red data points represent when the text/column feature is observed in a patient's records, whereas the blue represents when the feature is not observed.
```{python, fig = True,width=850, name = 'SHAP Cat/Text Summary',echo=False, evaluate=True,results = 'hidden'}

# this section plots the SHAP summary plot using only categorical&text features from the important features above

# pluck out the indices associated with each of the top features(from importance frame) into a list
feature_inds = [np.where([feature == model.feature_names[i] for i in range(len(model.feature_names))])[0][0] for feature in importance_frame.Feature]+[1]
# go through and find which of the top features are a text_col or cat_col.
# this is achieved by eliminating all numeric(non text/cat) columns
non_encoded_types = [col for col in list(trans.col_dict.keys()) if col not in ('text_cols','cat_cols','cat_from_text_cols')]
# keeps track of which of the top features aren't encoded
non_encoded_feats=[]
for feature in importance_frame.Feature:
    for type in non_encoded_types:
        if feature in trans.col_dict.get(type):
            non_encoded_feats.append(feature)

# extract encoded_feats by elimnating the non-encoded features from the important features
encoded_feats = [col for col in importance_frame.Feature if col not in non_encoded_feats]
plt.figure()
#plt.subplots_adjust(left=0, bottom=None, right=1, top=None, wspace=None, hspace=None)
encoded_feat_inds = [np.where([feature == model.feature_names[i] for i in range(len(model.feature_names))])[0][0] for feature in encoded_feats]+[1]
shap.summary_plot(shap_vals[:,encoded_feat_inds], samp_df.iloc[:,encoded_feat_inds], show=False)#,auto_size_plot=False
plt.subplots_adjust(left=.3, bottom=None, right=.95, top=None, wspace=None, hspace=None)
plt.show
```
